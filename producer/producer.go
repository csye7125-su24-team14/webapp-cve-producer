package producer

import (
	"net/http"
	"os"
	"strconv"
	"strings"

	"github.com/Shopify/sarama"
	"github.com/joho/godotenv"
	zlog "github.com/rs/zerolog/log"
)

var producer sarama.SyncProducer

func init() {
	// loads values from .env into the system
	if err := godotenv.Load(); err != nil {
		zlog.Info().Msg("sad .env file found")
		// log.Print("sad .env file found")
	}
}

func Main() {
	brokersUrl := strings.Split(os.Getenv("kafkaURL"), ",")
	// brokersUrl := []string{
	// 	"mykafka-controller-0.mykafka-controller-headless.default.svc.cluster.local:9092",
	// 	"mykafka-controller-1.mykafka-controller-headless.default.svc.cluster.local:9092",
	// 	"mykafka-controller-2.mykafka-controller-headless.default.svc.cluster.local:9092",
	// }
	var err error
	topic := os.Getenv("TOPIC_NAME")
	producer, err := ConnectProducer(brokersUrl, topic)
	if err != nil {
		// log.Fatalf("Failed to connect to Kafka producer: %v", err)
		zlog.Fatal().Err(err).Msg("Failed to connect to Kafka producer")
	}
	defer producer.Close()
	SaveCve(producer, topic)

	resp, err := http.Get("http://127.0.0.1:15000/ready")
	if err != nil {
		zlog.Info().Msgf("Failed to check Envoy readiness: %v", err)
	} else if resp.StatusCode == http.StatusOK {
		zlog.Info().Msgf("Envoy is ready")
		resp, err := http.Post("http://127.0.0.1:15000/quitquitquit", "application/json", nil)
		if err != nil {
			zlog.Warn().Err(err).Msg("Failed to stop Envoy sidecar")
		}
		defer resp.Body.Close()

		if resp.StatusCode != http.StatusOK {
			zlog.Info().Msgf("Failed to stop Envoy sidecar, status code: %d", resp.StatusCode)
		}

		zlog.Info().Msgf("Envoy sidecar stopped successfully")

	} else {
		zlog.Info().Msgf("Envoy not ready, status code: %d", resp.StatusCode)
	}

}

func ConnectProducer(brokersUrl []string, topic string) (sarama.SyncProducer, error) {

	config := sarama.NewConfig()
	// config.Version = sarama.V2_6_0_0
	config.Producer.Return.Successes = true
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Retry.Max = 5
	// SASL configuration
	config.Net.SASL.Enable = true
	config.Net.SASL.Mechanism = sarama.SASLTypeSCRAMSHA256
	config.Net.SASL.User = os.Getenv("USERNAME")
	config.Net.SASL.Password = os.Getenv("PASSWORD")

	config.ClientID = "sasl_scram_client"
	config.Metadata.Full = true

	config.Net.SASL.Handshake = true

	config.Net.SASL.SCRAMClientGeneratorFunc = func() sarama.SCRAMClient { return &XDGSCRAMClient{HashGeneratorFcn: SHA256} }

	// nf.Net.SASL.SCRAMClientGeneratorFunc =
	// conf.Net.SASL.Mechanism = sarama.SASLTypeSCRAMSHA256

	// if *useTLS {
	// 	conf.Net.TLS.Enable = true
	// 	conf.Net.TLS.Config = createTLSConfiguration()
	admin, err := sarama.NewClusterAdmin(brokersUrl, config)
	if err != nil {
		zlog.Fatal().Err(err).Msg("Failed to create Kafka admin client")
		// log.Fatalf("Failed to create Kafka admin client: %v", err)
	}
	defer func() {
		if err := admin.Close(); err != nil {
			zlog.Fatal().Err(err).Msg("Failed to close Kafka admin client")
			// log.Fatalf("Failed to close Kafka admin client: %v", err)
		}
	}()

	partitionsEnv := os.Getenv("PARTITIONS")
	numPartitions, err := strconv.Atoi(partitionsEnv)
	if err != nil {
		numPartitions = 3
		// log.Println("Invalid PARTITIONS value:", err)
		zlog.Warn().Err(err).Msg("Invalid PARTITIONS value")
	}
	replicasEnv := os.Getenv("REPLICAS")
	replicationFactor, err := strconv.Atoi(replicasEnv)
	if err != nil {
		replicationFactor = 3
		// log.Println("Invalid replicasEnv value:", err)
		zlog.Warn().Err(err).Msg("Invalid replicasEnv value")
	}

	topics, err := admin.ListTopics()
	if err != nil {
		// log.Fatal("Failed to list topics:", err)
		zlog.Fatal().Err(err).Msg("Failed to list topics")
	}

	if _, exists := topics[topic]; !exists {
		// Create the topic
		topicDetail := &sarama.TopicDetail{
			NumPartitions:     int32(numPartitions),
			ReplicationFactor: int16(replicationFactor),
		}

		err = admin.CreateTopic(topic, topicDetail, false)
		if err != nil {
			// log.Fatalf("Failed to create topic: %v", err)
			zlog.Fatal().Err(err).Msg("Failed to create topic")
		}
		zlog.Info().Msg("Topic " + topic + " created successfully")
		// fmt.Printf("Topic %s created successfully\n", topic)
	} else {
		zlog.Info().Msg("Topic " + topic + " already exists")
		// fmt.Printf("Topic %s already exists\n", topic)
	}

	topics, err = admin.ListTopics()
	if err == nil {
		zlog.Info().Msg("Existing topics and their details:")
		// fmt.Println("Existing topics and their details:")
		for topic, details := range topics {
			zlog.Info().Msgf("Topic: %s, Details: %+v", topic, details)
			// fmt.Printf("Topic: %s, Details: %+v\n", topic, details)
		}

	}
	conn, err := sarama.NewSyncProducer(brokersUrl, config)
	if err != nil {
		return nil, err
	}

	return conn, nil
}

func PushCveToQueue(topic string, key string, cve []byte, producer sarama.SyncProducer) error {

	msg := &sarama.ProducerMessage{
		Topic: topic,
		Key:   sarama.StringEncoder(key),
		Value: sarama.StringEncoder(cve),
	}

	partition, offset, err := producer.SendMessage(msg)
	if err != nil {
		return err
	}
	zlog.Info().Msgf("Message is stored in topic(%s)/partition(%d)/offset(%d)", topic, partition, offset)
	// fmt.Printf("Message is stored in topic(%s)/partition(%d)/offset(%d)\n", topic, partition, offset)

	return nil
}
